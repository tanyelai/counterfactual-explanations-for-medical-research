{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from scipy import stats\n",
    "import os\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import matplotlib.mlab as mlab\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline\n",
    "\n",
    "root_dir = \"/your/path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(f\"{root_dir}/figures\")\n",
    "except OSError as error: \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.mkdir(f\"{root_dir}/figures/dependent\")\n",
    "except OSError as error:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_features(root_dir):\n",
    "    dataset = pd.read_excel(f\"{root_dir}/data/file.xlsx\")\n",
    "    dataset[\"TUMOR_TYPE\"] = dataset[\"TUMOR_TYPE\"].apply(lambda x: \"MB\" if x == \"MEDULLOBLASTOMA\" else x)\n",
    "    dataset[\"TUMOR_TYPE\"] = dataset[\"TUMOR_TYPE\"].apply(lambda x: \"EP\" if x == \"EPENDYMOMA\" else x)\n",
    "    dataset[\"TUMOR_TYPE\"] = dataset[\"TUMOR_TYPE\"].apply(lambda x: \"PA\" if x == \"PILOCYTIC ASTROCYTOMA\" else x)\n",
    "    dataset[\"TUMOR_TYPE\"] = dataset[\"TUMOR_TYPE\"].apply(lambda x: \"BG\" if x == \"GLIOMA\" else x)\n",
    "    filtered_mb = dataset[dataset[\"TUMOR_TYPE\"] == \"MB\"].head(25)\n",
    "    filtered_ep = dataset[dataset[\"TUMOR_TYPE\"] == \"EP\"]\n",
    "    filtered_pa = dataset[dataset[\"TUMOR_TYPE\"] == \"PA\"].head(25)\n",
    "    filtered_bg = dataset[dataset[\"TUMOR_TYPE\"] == \"BG\"].head(25)\n",
    "    return filtered_mb, filtered_ep, filtered_pa, filtered_bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_mb, filtered_ep, filtered_pa, filtered_bg = get_original_features(root_dir)\n",
    "filtered_mb.name = \"MB\"\n",
    "filtered_ep.name = \"EP\"\n",
    "filtered_pa.name = \"PA\"\n",
    "filtered_bg.name = \"BG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_labels(dataset):\n",
    "    dataset[\"TUMOR_TYPE\"] = dataset[\"TUMOR_TYPE\"].apply(lambda x: \"MB\" if x == 0 else x)\n",
    "    dataset[\"TUMOR_TYPE\"] = dataset[\"TUMOR_TYPE\"].apply(lambda x: \"EP\" if x == 1 else x)\n",
    "    dataset[\"TUMOR_TYPE\"] = dataset[\"TUMOR_TYPE\"].apply(lambda x: \"PA\" if x == 2 else x)\n",
    "    dataset[\"TUMOR_TYPE\"] = dataset[\"TUMOR_TYPE\"].apply(lambda x: \"BG\" if x == 3 else x)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_features(root_dir, original, desired):\n",
    "    file_path = f'{root_dir}/counterfactuals/statistics_of_cfes/{original}/{original}_to_{desired}_summary.txt'\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        file_content = file.read()\n",
    "\n",
    "    # Extract the max counted 3 features using regex\n",
    "    pattern = r\"^(.+?): \\d+ changes$\"  # Regex pattern to match the feature lines\n",
    "    matches = re.findall(pattern, file_content, flags=re.MULTILINE)\n",
    "\n",
    "    # We have already sorted the features by their counts in the file, so\n",
    "    # We can extract the max counted 3 feature names as a list\n",
    "    max_counted_3_features = matches[:3]\n",
    "\n",
    "    return max_counted_3_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_gaussian_dists(root_dir, original_data_dict, original, desired, first_three_features):\n",
    "    \n",
    "    palette = \"mako\"\n",
    "    common_norm = False\n",
    "    alpha = 0.3\n",
    "    linewidth = 0.9\n",
    "    label_size = 18\n",
    "\n",
    "    for name, data in original_data_dict.items():\n",
    "        for feature in first_three_features:\n",
    "    \n",
    "            # Convert the columns to numeric data types\n",
    "            data[feature] = pd.to_numeric(data[feature])\n",
    "            data = data.rename(columns={'TUMOR_TYPE': 'Tumor Type'})\n",
    "\n",
    "            ### KDE ###\n",
    "        \n",
    "            # Save the results\n",
    "            filename_pdf = f'{root_dir}/figures/dependent/{name}_{feature}.pdf'\n",
    "            filename_png = f'{root_dir}/figures/dependent/{name}_{feature}.png'\n",
    "\n",
    "            print(f\"Plotting {desired} {feature} KDE\")\n",
    "            plt.figure(dpi=300)\n",
    "            sns.set_style('dark', {'axes.grid' : False})\n",
    "            with sns.plotting_context(rc={\"axes.labelsize\": label_size}):\n",
    "                sns_hist = sns.kdeplot(\n",
    "                    data=data, x=feature, hue=\"Tumor Type\",\n",
    "                    fill=True, palette=palette, common_norm=common_norm, alpha=alpha, linewidth=linewidth\n",
    "                )\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(filename_pdf)\n",
    "            plt.savefig(filename_png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "original_class = [\"MB\", \"EP\", \"BG\", \"PA\"]\n",
    "desired_class = [\"MB\", \"EP\", \"BG\", \"PA\"]\n",
    "\n",
    "original_data_list = [filtered_mb, filtered_ep, filtered_bg, filtered_pa]\n",
    "\n",
    "paired_datasets = {}\n",
    "for dataset1, dataset2 in itertools.combinations(original_data_list, 2):\n",
    "    concatenated_dataset = pd.concat([dataset1, dataset2], ignore_index=True)\n",
    "    pair_name = f\"{dataset1.name}_{dataset2.name}\"\n",
    "    paired_datasets[pair_name] = concatenated_dataset\n",
    "\n",
    "for original in original_class:\n",
    "    for desired in desired_class:\n",
    "        if original != desired:\n",
    "            best_features = get_best_features(root_dir, original, desired)\n",
    "            get_gaussian_dists(root_dir, paired_datasets, original, desired, best_features)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
