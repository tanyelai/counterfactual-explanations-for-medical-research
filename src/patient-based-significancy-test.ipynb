{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one vs its cfes individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from scipy import stats\n",
    "import os\n",
    "\n",
    "root_dir = \"/your/path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(f\"{root_dir}/counterfactuals/1-ttests_of_cfes\")\n",
    "except OSError as error: \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_labels(dataset):\n",
    "    dataset[\"TUMOR_TYPE\"] = dataset[\"TUMOR_TYPE\"].apply(lambda x: \"MB\" if x == 0 else x)\n",
    "    dataset[\"TUMOR_TYPE\"] = dataset[\"TUMOR_TYPE\"].apply(lambda x: \"EP\" if x == 1 else x)\n",
    "    dataset[\"TUMOR_TYPE\"] = dataset[\"TUMOR_TYPE\"].apply(lambda x: \"PA\" if x == 2 else x)\n",
    "    dataset[\"TUMOR_TYPE\"] = dataset[\"TUMOR_TYPE\"].apply(lambda x: \"BG\" if x == 3 else x)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_features(root_dir, original, desired):\n",
    "    file_path = f'{root_dir}/counterfactuals/statistics_of_cfes/{original}/{original}_to_{desired}_summary.txt'\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        file_content = file.read()\n",
    "\n",
    "    # Extract the max counted 5 features using regex\n",
    "    pattern = r\"^(.+?): \\d+ changes$\"  # Regex pattern to match the feature lines\n",
    "    matches = re.findall(pattern, file_content, flags=re.MULTILINE)\n",
    "\n",
    "    # We have already sorted the features by their counts in the file, so\n",
    "    # We can extract the max counted 5 feature names as a list\n",
    "    max_counted_5_features = matches[:5]\n",
    "\n",
    "    return max_counted_5_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "from openpyxl.styles import Alignment\n",
    "\n",
    "def adjust_column_width_and_center(excel_file):\n",
    "    # Load the workbook\n",
    "    workbook = openpyxl.load_workbook(excel_file)\n",
    "\n",
    "    # Iterate over each sheet in the workbook\n",
    "    for sheet_name in workbook.sheetnames:\n",
    "        worksheet = workbook[sheet_name]\n",
    "\n",
    "        # Iterate over each column in the sheet\n",
    "        for column in worksheet.columns:\n",
    "            max_length = 0\n",
    "\n",
    "            # Find the maximum length of the cell values in the column\n",
    "            for cell in column:\n",
    "                try:\n",
    "                    if len(str(cell.value)) > max_length:\n",
    "                        max_length = len(str(cell.value))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            # Adjust the column width based on the maximum length\n",
    "            adjusted_width = (max_length + 2) * 1.2\n",
    "            column_letter = column[0].column_letter\n",
    "            worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "\n",
    "            for cell in column:\n",
    "                cell.alignment = openpyxl.styles.Alignment(horizontal='center', vertical='center', wrap_text=True)\n",
    "\n",
    "    # Save the modified workbook\n",
    "    workbook.save(excel_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_ttest(root_dir, original_data, counterfactuals, original, desired):\n",
    "    results_df = pd.DataFrame(columns=['Original Case', 'Generated Case', 'Features', 'T-Statistic', 'P-Value', 'Statistical Significance'])\n",
    "\n",
    "    # Initialize the pattern count\n",
    "    not_significant_count = 0\n",
    "    significant_count = 0\n",
    "    best_features = get_best_features(root_dir, original, desired)\n",
    "\n",
    "    # Extract the max counted 5 features from the list\n",
    "    best_original_data = original_data[best_features].to_numpy(dtype=np.float64)\n",
    "    best_counterfactuals = counterfactuals[best_features].to_numpy(dtype=np.float64)\n",
    "\n",
    "    if original != desired:\n",
    "        for counterfactual in best_counterfactuals:\n",
    "            # Perform the t-test\n",
    "            print(f\"Original {original} and generated {original} to {desired} CFE populations are being tested...\")\n",
    "            print(f\"best_original_data: {best_original_data}\")\n",
    "            print(f\"counterfactual: {counterfactual}\")\n",
    "            t_statistic, p_value = stats.ttest_rel(best_original_data, counterfactual)\n",
    "\n",
    "            # Print the results\n",
    "            result = f\"T-Statistic: {t_statistic}\\n\"\n",
    "            result += f\"P-Value: {p_value}\\n\"\n",
    "\n",
    "            if p_value < 0.05:\n",
    "                result += f\"The difference between original {original} and generated {original} to {desired} CFE populations is statistically significant.\\n\"\n",
    "                significant_count += 1\n",
    "            else:\n",
    "                result += f\"There is no statistically significant difference between original {original} and generated {original} to {desired} CFE populations.\\n\"\n",
    "                not_significant_count += 1\n",
    "\n",
    "            # Save the results to a text file\n",
    "            filename_txt = f'{root_dir}/counterfactuals/1-ttests_of_cfes/CFE_{desired}.txt'\n",
    "            with open(filename_txt, 'a') as file:\n",
    "                file.write(result)\n",
    "                file.write(\"Significance Counts:\\n\")\n",
    "                file.write(f\"Significant: {significant_count}\\n\")\n",
    "                file.write(f\"Not Significant: {not_significant_count}\\n\\n\")\n",
    "\n",
    "\n",
    "            # Create a dictionary with the result information\n",
    "            result_dict = {\n",
    "                'Original Case': original,\n",
    "                'Generated Case': f\"{original} to {desired}\",\n",
    "                'Features': best_features,\n",
    "                'T-Statistic': t_statistic,\n",
    "                'P-Value': p_value,\n",
    "                'Statistical Significance': \"Statistically significant\" if p_value < 0.05 else \"Not statistically significant\",\n",
    "                'Significant': significant_count,\n",
    "                'Not Significant': not_significant_count\n",
    "            }\n",
    "\n",
    "            # Append the result to the DataFrame\n",
    "            results_df = results_df.append(result_dict, ignore_index=True)\n",
    "\n",
    "        # Save the results to an Excel file\n",
    "        filename_excel = f'{root_dir}/counterfactuals/1-ttests_of_cfes/CFE_{original}_to_{desired}.xlsx'\n",
    "        if os.path.isfile(filename_excel):\n",
    "            existing_data = pd.read_excel(filename_excel)\n",
    "            results_df = pd.concat([existing_data, results_df], ignore_index=True)\n",
    "        results_df.to_excel(filename_excel, index=False)\n",
    "        adjust_column_width_and_center(filename_excel)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_class = [\"MB\", \"EP\", \"PA\", \"BG\"]\n",
    "desired_class = [\"MB\", \"EP\", \"PA\", \"BG\"]\n",
    "\n",
    "\n",
    "for original in original_class:\n",
    "    for desired in desired_class:\n",
    "        read_file = f'{root_dir}/counterfactuals/formatted_cfe_from_json/{original}/{original}_to_{desired}_merged_data.xlsx'\n",
    "        write_file = f'{root_dir}/counterfactuals/1-ttests_of_cfes/{original}/{original}_to_{desired}.xlsx'\n",
    "\n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(read_file)\n",
    "        df = change_labels(df)\n",
    "\n",
    "        # Create a new DataFrame to store the baseline row\n",
    "        baseline_row = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "        # Create a new DataFrame to store the counterfactuals\n",
    "        cfe_rows = pd.DataFrame(columns=df.columns)\n",
    "        \n",
    "        # Iterate over the rows\n",
    "        for i, row in df.iterrows():\n",
    "            # Check if the row is a baseline row\n",
    "            if i % 6 == 0:\n",
    "                if row['TUMOR_TYPE'] == original:\n",
    "                    baseline_row = df.iloc[i, :-1]\n",
    "                    cfe_rows = df.iloc[i+1:i+6, :-1]\n",
    "                    perform_ttest(root_dir, baseline_row, cfe_rows, original, desired)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
