## Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research
#### What if we could know what might happen in alternative scenarios in the decision space?

These codes can be utilized as a baseline for diverse studies or just to gain insights about possible approaches with the counterfactual idea. The counterfactual methods already have generic examples, such as DiCE and MACE, but lack specific applications for different kinds of usage. We have also provided utility codes for handling JSON files generated by DiCE.

### Introduction

Medical research and diagnostics have witnessed substantial advancements with the integration of machine learning algorithms. However, the growing complexity of these algorithms has often resulted in a lack of transparency and interpretability, which has impeded their acceptance and adoption in clinical practice. The interpretability of machine learning models is of utmost importance, especially when it comes to critical domains such as pediatric brain tumor diagnosis using MRI features in the posterior fossa.

### Motivation

The motivation behind this research is to address the challenges posed by the lack of human-friendly interpretability in existing machine learning algorithms across various medical domains. End-users, such as clinicians and patients, might exhibit greater interest in comprehending the real-world consequences of the ML model's predictions in their own context, rather than solely focusing on the technical details of how the predictions were generated. For instance, patients might not only desire to know if they are sick, but also seek advice on how to be healthy again. They are less concerned about understanding the decision-making process of either the clinician or the ML algorithm.


### Citation

If you use our work or find it relevant to your research, please consider citing our paper:

@misc{tanyel2023known,<br/>
      title={Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research}, <br/>
      author={Toygar Tanyel and Serkan Ayvaz and Bilgin Keserci},<br/>
      year={2023},<br/>
      eprint={2307.02131},<br/>
      archivePrefix={arXiv},<br/>
      primaryClass={cs.AI}<br/>
}
